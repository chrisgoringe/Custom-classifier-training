# Different hidden layers

Training on training4 with 

```python
    "meta_trials"       : 200,
    "sampler"           : "CmaEs", 
    "num_train_epochs"   : (5, 50),
    "warmup_ratio"       : (0.0, 0.2),
    "log_learning_rate"  : (-3.5, -1.5),
    "half_batch_size"    : (1, 50),           
    "dropouts"           : [ (0.0, 0.8), (0.0, 0.8), ],
    "hidden_layers"      : [ (10, 1000), (10, 1000), ],
```

Hidden layer 0 is the default behaviour

|Hidden layer(s)|Loss|AB|Spearman|
|-|-|-|-|
|0|0.2721|77.96%|0.7631|
|0+0|0.2723|77.71%|0.7598|
|1|0.2714|77.84%|0.7631|
|0+1|0.2678|78.09%|0.7694|
|2|0.2762|77.99%|0.7626|
|0+2|0.2704|77.83%|0.7627|
|0+1+2|0.2702|77.95%|0.7636|
|3|0.2857|77.07%|0.7416|
|16|0.3558|73.00%|0.6577|

Trained weights of last n layers - 500 trials

|n|Loss|AB|Spearman|weights|
|-|-|-|-|-|
|1|0.2694|77.86%|0.7632|
|2|0.2715|77.71%|0.7627|0.2450, 0.0101|
|3|0.2635|78.19%|0.7682|0.3157, -0.2245, 0.3599|
|4|0.2672|77.93%|0.7609|-0.2702, -0.3529, 0.2533, -0.2148|
|5|0.2663|78.07%|0.7709|-0.2517, -0.2511, 0.4187, 0.1651, 0.4474|
|8|0.2741|77.68%|0.7577|0.0093, -0.2547, 0.0963, -0.1376, 0.0929, -0.0893, 0.2775, -0.2261|

## Runs with n = 4

|Loss|AB|Spearman|weights|
|-|-|-|-|
|0.2672|77.93%|0.7609|-0.2702,-0.3529, 0.2533, -0.2148|
|0.2685|78.01%|0.7671| 0.2671,-0.4090,-0.2720,  0.1317|
|0.2623|78.06%|0.7665| 0.0214,-0.3513, 0.1440, -0.1832|

## Runs with n = 3

|Loss|AB|Spearman|weights|
|-|-|-|-|
|0.2635|78.19%|0.7682| 0.3157, -0.2245, 0.3599|